{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSo4wX84BAkz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "# import wandb\n",
        "from torchvision.models import VisionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVhCzjVeBCjt",
        "outputId": "24ee9421-f14e-4184-d1df-2318558fac48"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QiPXkWuBG2i",
        "outputId": "f1056072-0e5b-424f-bbf8-c027feda54c7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"../../preprocessing/icdas_preprocessed\"\n",
        "## Load the testing & training data from data_npy folder# Directory Names\n",
        "dir_training = '{}/training'.format(path)\n",
        "dir_testing = '{}/testing'.format(path)\n",
        "file_name = ''\n",
        "import numpy\n",
        "\n",
        "import gc\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "## 4 class\n",
        "\n",
        "class ToothDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.dataset_path = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.dataset_path))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(os.listdir(self.dataset_path)):\n",
        "            print(\"No datafile/image at index: \" + str(idx))\n",
        "            return None\n",
        "        \n",
        "        npy_filename = os.listdir(self.dataset_path)[idx]\n",
        "        # print(npy_flename)\n",
        "        \n",
        "        # print(npy_filename)\n",
        "        # file_name = npy_filename\n",
        "        label = int(npy_filename[-5]) - 3  # Extract the last digit and convert to class label\n",
        "        \n",
        "        numpy_arr = numpy.load(self.dataset_path + '/' + npy_filename)\n",
        "        # file_name = npy_filename\n",
        "        \n",
        "        for i in range(numpy_arr.shape[0] - 70):\n",
        "            numpy_arr = numpy.delete(numpy_arr, [0], axis=0)\n",
        "            \n",
        "        numpy_arr = numpy_arr.reshape(1, 70, 70, 70)\n",
        "        tensor_arr = torch.from_numpy(numpy_arr).to(torch.float32)\n",
        "\n",
        "        del numpy_arr \n",
        "        gc.collect()\n",
        "        \n",
        "        if self.transform:\n",
        "            tensor_arr = self.transform(tensor_arr)  # Apply transformations\n",
        "        print(npy_filename, label)\n",
        "        # pass the filename as well\n",
        "        return tensor_arr.to(torch.float32), torch.LongTensor([label])\n",
        "        # return tensor_arr.to(torch.float32), torch.tensor(label)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "epochs = 500\n",
        "batch_size = 1\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0000000001\n",
        "momentum = 0.9\n",
        "training_data = ToothDataset(img_dir=dir_training, transform=None)\n",
        "validation_data = ToothDataset(img_dir=dir_testing, transform=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data_loader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "validation_data_loader = DataLoader(validation_data, batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Basic3DCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(Basic3DCNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool3d(2, 2)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8 * 8, 256)  # Adjust input size based on pooling\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # Flatten the output\n",
        "        x = x.view(-1, 64 * 8 * 8 * 8)  # Adjust output size based on pooling\n",
        "        # Fully connected layers with ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IroDNAFoQtFG",
        "outputId": "4f101253-02ce-44c9-e11c-fed7cc97a79f"
      },
      "outputs": [],
      "source": [
        "# from pytorch_pretrained_vit import ViT\n",
        "# pretrained_model = ViT('B_16_imagenet1k', pretrained=True)\n",
        "\n",
        "model = Basic3DCNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_lzTzUKRAYw"
      },
      "outputs": [],
      "source": [
        "# model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load('../best_model_epoch_63_accuracy_94.44.pt', map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "from skimage import measure\n",
        "import torch\n",
        "from captum.attr import Saliency\n",
        "import meshio\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "\n",
        "def generateAndSaveSaliencyMap(model, data, target, file_name):\n",
        "    global threshold\n",
        "    # global file_name\n",
        "    \n",
        "    # set a bool correct to check if the model's prediction is correct\n",
        "    correct = False\n",
        "    # Get model's prediction\n",
        "    output = model(data)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    if predicted == target:\n",
        "        correct = True\n",
        "        \n",
        "    print(f'Predicted: {predicted.item()} Target: {target} Correct: {correct}')\n",
        "    \n",
        "    # store the directory path\n",
        "    if correct:\n",
        "        directory = file_name[:-4] + \"[correct]/\"\n",
        "        \n",
        "    else:\n",
        "        directory = file_name[:-4] + \"/\"\n",
        "    \n",
        "    # create the directory if it does not exist\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    \n",
        "    #store the path of the file to be saved\n",
        "    file_name = directory + file_name[:-4] + \"_saliency_map.stl\"\n",
        "\n",
        "    # Generate saliency map\n",
        "    saliency = Saliency(model)\n",
        "    saliency_map = saliency.attribute(data, target=target)\n",
        "    \n",
        "    print(saliency_map.shape)\n",
        "\n",
        "    # Move saliency map to CPU and convert to numpy array\n",
        "    saliency_map = saliency_map.cpu().detach().numpy().squeeze()\n",
        "\n",
        "    # Calculate threshold value as the 70% percentile of the saliency map\n",
        "    threshold = np.percentile(saliency_map, 99.5)\n",
        "    # print(threshold)\n",
        "\n",
        "    # Create a 3D isosurface from the saliency map\n",
        "    verts, faces, _, _ = measure.marching_cubes(saliency_map, threshold)\n",
        "\n",
        "    # Create a figure with a 3D plot\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Create a 3D isosurface from the saliency map\n",
        "    mesh = Poly3DCollection(verts[faces], alpha=0.4)\n",
        "    face_color = [1.0, 0.647, 0.0]  # color of the saliency map surface\n",
        "    mesh.set_facecolor(face_color)\n",
        "    ax.add_collection3d(mesh)\n",
        "\n",
        "    # Create a 3D isosurface from the original data\n",
        "    original_verts, original_faces, _, _ = measure.marching_cubes(\n",
        "        data.cpu().detach().numpy().squeeze(), 0.5)\n",
        "\n",
        "    # Create a 3D isosurface from the original STL file\n",
        "    original_mesh = Poly3DCollection(original_verts[original_faces], alpha=0.4)\n",
        "    original_face_color = [0.5, 0.5, 1]  # color of the original surface\n",
        "    original_mesh.set_facecolor(original_face_color)\n",
        "    ax.add_collection3d(original_mesh)\n",
        "\n",
        "    # Set limits and labels of the plot\n",
        "    max_dim = np.max(np.vstack([original_verts, verts]), axis=0)\n",
        "    ax.set_xlim(0, max_dim[0])\n",
        "    ax.set_ylim(0, max_dim[1])\n",
        "    ax.set_zlim(0, max_dim[2])\n",
        "    ax.set_xlabel(\"X-axis\")\n",
        "    ax.set_ylabel(\"Y-axis\")\n",
        "    ax.set_zlabel(\"Z-axis\")\n",
        "    \n",
        "    meshio.write(file_name, meshio.Mesh(\n",
        "        points=np.vstack([original_verts, verts]), cells=[(\"triangle\", np.vstack([original_faces, faces+len(original_verts)]))]))\n",
        "    \n",
        "    # remove _saliency.stl and add .stl\n",
        "    file_name = file_name[:-17] + \".stl\"\n",
        "    meshio.write(file_name, meshio.Mesh(\n",
        "        points=verts, cells=[(\"triangle\", faces)]))\n",
        "    #remove the .stl and add _original.stl\n",
        "    file_name = file_name[:-4] + \"_original.stl\"\n",
        "    meshio.write(file_name, meshio.Mesh(\n",
        "        points=original_verts, cells=[(\"triangle\", original_faces)]))\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "    # Free up memory\n",
        "    del saliency_map, verts, faces, mesh, original_mesh\n",
        "    gc.collect()\n",
        "    \n",
        "import os\n",
        "\n",
        "# Get a list of file names in the directory\n",
        "dir_path = '../../preprocessing/icdas_preprocessed/testing'  # replace with your directory path\n",
        "file_names = os.listdir(dir_path)\n",
        "\n",
        "# Iterate over the validation data loader\n",
        "for i, (data, target) in enumerate(validation_data_loader):\n",
        "    # print(file_names[i])\n",
        "    # pass\n",
        "    # Move data and target to the same device as your model\n",
        "    data = data.to(device)\n",
        "    target = target.to(device)\n",
        "    # Assuming 'data' is your data tensor\n",
        "    data_min = torch.min(data)\n",
        "    data_max = torch.max(data)\n",
        "\n",
        "    print(f'Data range: {data_min} to {data_max}')\n",
        "\n",
        "    # Use the file name from the directory for each data point\n",
        "    file_name = file_names[i]\n",
        "    \n",
        "    # set a bool correct to check if the model's prediction is correct\n",
        "\n",
        "    # Call the function\n",
        "    generateAndSaveSaliencyMap(model, data, target.item(), file_name)\n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
