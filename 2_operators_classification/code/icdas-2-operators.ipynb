{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7617323,"sourceType":"datasetVersion","datasetId":4436414}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport numpy\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\n\nimport gc\n\nfrom torch.optim.lr_scheduler import StepLR\n\nimport torchvision.transforms as T\nimport torchvision.transforms.functional as TF\n\nfrom torchvision.models.vision_transformer import VisionTransformer\n\nfrom pytorch_pretrained_vit import ViT","metadata":{"id":"SHJDyiS7PQ7v","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(20)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wSKVDATbPcwZ","outputId":"64c7300b-f3c4-4982-d5b4-abd16964d240","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device} device\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVjymfmCPm4X","outputId":"ea76c4fb-1c91-49a5-e1d8-951d9e79df4d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Directory Names\ndir_training = '/kaggle/input/icdas-70x70/icdas_preprocessed/training'\ndir_testing = '/kaggle/input/icdas-70x70/icdas_preprocessed/testing'","metadata":{"id":"Xyi6_qudPoGX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ToothDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.dataset_path = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(os.listdir(self.dataset_path))\n\n    def __getitem__(self, idx):\n        if idx  >= len(os.listdir(self.dataset_path)):\n            print(\"No datafile/image at index : \"+ str(idx))\n            return None\n        npy_filename = os.listdir(self.dataset_path)[idx]\n        label = int(npy_filename[3] == 'B')\n        \n        numpy_arr = numpy.load(self.dataset_path + '/' + npy_filename)\n        \n        for i in range(numpy_arr.shape[0]-70): numpy_arr = numpy.delete(numpy_arr, [0], axis=0)\n            \n        numpy_arr = numpy_arr.reshape(1, 70, 70, 70)\n        tensor_arr = torch.from_numpy(numpy_arr).to(torch.float32)\n\n        del numpy_arr \n        gc.collect()\n\n        if self.transform: tensor_arr = self.transform(tensor_arr) # Apply transformations\n\n        return tensor_arr.to(torch.float32), torch.LongTensor([label])","metadata":{"id":"HYJagPZOQeeM","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = ToothDataset(img_dir=dir_training, transform=None)\nvalidation_data = ToothDataset(img_dir=dir_testing, transform=None)","metadata":{"id":"Nr398yHVQhxT","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Basic3DCNN(nn.Module):\n    def __init__(self, num_classes=4):\n        super(Basic3DCNN, self).__init__()\n        # Convolutional layers\n        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n        # Max pooling layers\n        self.pool = nn.MaxPool3d(2, 2)\n        # Fully connected layers\n        self.fc1 = nn.Linear(64 * 8 * 8 * 8, 256)  # Adjust input size based on pooling\n        self.dropout = nn.Dropout(0.2)\n        self.fc2 = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        # Convolutional layers with ReLU activation and max pooling\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        # Flatten the output\n        x = x.view(-1, 64 * 8 * 8 * 8)  # Adjust output size based on pooling\n        # Fully connected layers with ReLU activation\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = NeuralNetwork().to(device)\nmodel = Basic3DCNN(num_classes=2).to(device)","metadata":{"id":"sRE_KuDDQnKG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datax = training_data[0][0].reshape(1,1,70,70,70).to(device)","metadata":{"id":"m7PQHq3TmJyX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(datax)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tszA-R18lGgS","outputId":"25e24891-937d-4122-aa8d-98d18200cb8f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters\nepochs = 500\nbatch_size = 2\nlearning_rate = 1e-3\nweight_decay = 0.0000000001\nmomentum=0.9","metadata":{"id":"Rju3Y47LQoaJ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam( model.parameters()  ,lr=learning_rate)\n# optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)","metadata":{"id":"iTnpPGvRQqiu","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\nvalidation_data_loader = DataLoader(validation_data, batch_size, shuffle = False)","metadata":{"id":"GINVboKiQr4k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n#     torch.cuda.empty_cache()\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n        \n        # Compute prediction error\n        pred = model(X)\n        \n        loss = loss_fn(pred, y.squeeze())\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch%5==0:\n          # Print\n          loss, current = loss.item(), batch * len(X)\n          print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"id":"j-XRPMtkQtM7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_accuracy = []\ndef validation(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y.squeeze()).item()\n            correct += (torch.argmax(pred, dim=1) == y.squeeze()).sum().item()\n            X.cpu()\n            y.cpu()\n    test_loss /= num_batches\n    correct /= size\n    validation_accuracy.append(correct*100)\n    # Print\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n    return correct*100","metadata":{"id":"qHD2Fgd2Qum-","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the directory to save the model\nsave_dir = \"/kaggle/working/saved_models\"\nif not os.path.exists(save_dir):\n    os.makedirs(save_dir)\n\nbest_accuracy = 0.0  # Initialize best validation accuracy\nbest_epoch = 0  # Initialize the epoch with the best validation accuracy\n\n# Training\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(training_data_loader, model, loss_function, optimizer)\n    accuracy = validation(validation_data_loader, model, loss_function)\n    \n    # Save the model for every 50th epoch\n    if (t + 1) % 100 == 0:\n        save_path = os.path.join(save_dir, f\"model_epoch_{t+1}_accuracy_{accuracy:.2f}.pt\")\n        torch.save(model.state_dict(), save_path)\n        print(f\"Model saved at epoch {t+1}\")\n    \n    # Check if the current accuracy is better than the best accuracy\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_epoch = t + 1\n        best_model_path = os.path.join(save_dir, f\"best_model_epoch_{best_epoch}_accuracy_{best_accuracy:.2f}.pt\")\n        torch.save(model.state_dict(), best_model_path)\n        print(f\"Best model saved with accuracy: {best_accuracy:.2f} at epoch {best_epoch}\")\n\nprint(\"Training done!\")\nprint(f\"Best validation accuracy: {best_accuracy:.2f} at epoch {best_epoch}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"abgBr-mVRqHh"},"execution_count":null,"outputs":[]}]}